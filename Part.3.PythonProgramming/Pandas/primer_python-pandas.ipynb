{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pandas - Python data analysis library\n",
    "\n",
    "**Author: Trevor Faske, Chandra Sarkar  \n",
    "Modified: 02/15/2022**\n",
    "\n",
    "pandas is a must learn tool for data science. It is a powerful python package and swiss army knife for all data analysis. \"The name is derived from the term 'panel data', an econometrics term for data sets that include observations over multiple time periods for the same individuals. Also a play on the phrase 'Python data analysis.'\" - wikipedia\n",
    "\n",
    "pandas works with the data structure called **DataFrame** (same as in R). This consists of a matrix with rows and columns and will very similar to an excel spreadsheet or csv file. pandas allows you to easily manipulate, filter, summarize, and merge data for downstream processing. pandas is part of the SciPy (https://www.scipy.org/) ecosystem so works great for plotting and data analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- https://github.com/jvns/pandas-cookbook\n",
    "- https://www.w3schools.com/python/ (great NumPy intro)\n",
    "- https://pandas.pydata.org/docs/getting_started/tutorials.html (community tutorials)\n",
    "- https://pandas.pydata.org/docs/user_guide/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing libraries\n",
    "\n",
    "Python is extremely efficient and only has a few commands loaded and installed from the beginning. There are libraries we will have to install and import as needed to use. \n",
    "\n",
    "Everyone should have pip3 or conda available and these commands will be used to install needed libraries from the terminal. \n",
    "\n",
    "**If using pip3**:  \n",
    "\n",
    "`$ pip3 install numpy`   \n",
    "`$ pip3 install pandas`\n",
    "    \n",
    "You might get a permissions error. If so, install like:  \n",
    "`$ pip3 install --user pandas`\n",
    "\n",
    "**If using conda**:  \n",
    "\n",
    "`$ conda install -c anaconda numpy`  \n",
    "`$ conda install -c anaconda pandas`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries\n",
    "\n",
    "Python only has a few base commands and is extremely effecient. Libraries must be imported before use to make the commands available. There is a few ways to import libraries by creating aliases or only accessing paticular functions within libraries. \n",
    "\n",
    "Basic import: \n",
    "\n",
    "`import numpy`  \n",
    "`import pandas`  \n",
    "\n",
    "\n",
    "Examples of more common ways of importing:  \n",
    "\n",
    "`import numpy,pandas` #import multiple libraries in single line  \n",
    "`import numpy as np` #import package as alias  \n",
    "`from pandas import DataFrame` #import only specific function from library\n",
    "\n",
    "Common aliases you will see when searching issues:  \n",
    "\n",
    "`import numpy as np`  \n",
    "`import pandas as pd`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started with NumPy\n",
    "\n",
    "#### Resource: https://www.w3schools.com/python/numpy_intro.asp\n",
    "\n",
    "NumPy is a popular array â€“ processing package of Python that also does a lot of mathmatical processes. Everything is array/matrix based and works faster than a list. pandas uses many of this same syntax so might be useful to know a few commands!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ndarrays\n",
    "\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create 1-D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = np.array([1,3,5,2,4,6])\n",
    "print(d1)\n",
    "type(d1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create 2-D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = np.array([[1,3,5],[2,4,6]])\n",
    "print(d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get dimensions and total size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(d2.shape) #rows, columns\n",
    "print(d2.size) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing and indexing arrays work very similar to lists but with added dimension. Very similar to R indexing \n",
    "\n",
    "array[row,column] #REMEMBER starts at 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd row, 1st column \n",
    "print(d2[1,0]) \n",
    "\n",
    "# 1st row, 3rd column\n",
    "print(d2[0,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slicing works very similarly to lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract first 2 elements of the 2nd row\n",
    "print(d2[1,:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### arange and reshape array format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = np.array([1,3,5,2,4,6])\n",
    "print(d1)\n",
    "d1.reshape(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2.reshape(1,6)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create 1D array 0-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### array 0 to 50 by 5 (start,stop,step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0,51,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random number generator\n",
    "\n",
    "very useful for permutation techniques or simulating data\n",
    "\n",
    "import random from numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate a random float from 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.rand()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate 5 random float from 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.rand(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate random integer between 0-99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.randint(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate 7 random integer between 0-99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.randint(100, size = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate 2D array random integer between 0-99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.randint(100, size=(2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose or randomly sample list/array\n",
    "\n",
    "#### sample from list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.choice([3, 5, 7, 9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sample 4 elements from list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.choice([3, 5, 7, 9],size=(3,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Math (https://numpy.org/doc/stable/reference/routines.math.html)\n",
    "\n",
    "#### generate 100 random numbers from 1 to 1000 and get length, max, min, mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = random.randint(1000,size=100)\n",
    "\n",
    "print(len(x))\n",
    "print(x.max())\n",
    "print(x.min())\n",
    "print(x.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started with pandas - finally to the good stuff! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### side note: \n",
    "\n",
    "Nice thing about jupyter notebooks is it accepts linux commands, just as the terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Change to pandas working directory\n",
    "pandas_dir = '/home/chandra/2020Jan/BioInfoClass/Data_Science_For_Biology_II_old/Part.3.PythonProgramming/Pandas/Pandas_teach'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd $pandas_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir new_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rmdir new_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and write files (using DataFrame) \n",
    "\n",
    "Make sure you have **states_covid.csv** in your pandas directory from above.  \n",
    "\n",
    "Data downloaded from: https://github.com/COVID19Tracking/covid-tracking-data (data stopped updating March, 2021)  \n",
    "\n",
    "**PATH**: You need your path to be correct to load files. Go to directory for day 5 in your terminal and type `pwd`. Copy this path in front of **states_covid.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "state_covid_df = pd.read_csv('states_covid.csv') #read in csv\n",
    "state_covid_df.head() #views the top 5 lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_covid_df.shape #row, column length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_covid_df.columns #views the column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the above example is very straight forward with a clean csv file, **pd.read_csv()** is a very powerful tool for reading/parsing complicated data. For more information of all the commands it has, visit here: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html. Otherwise, google is your best friend. Any issue you have, someone has figured it out already. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One common issue with all data formats are Dates. Pandas has a way to read dates in without much headache and nice features for doing things with dates. You can also only select various columns, rename headers, remove headers, change what characters you want to be recognized as NAs, etc.\n",
    "\n",
    "Below is an example of some of the things you can do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_covid_sub_df = pd.read_csv('states_covid.csv',usecols=['date','state','death','positive','negative','totalTestResults'],parse_dates=['date'],infer_datetime_format=True)\n",
    "state_covid_sub_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check and make sure dtypes are right (dates specifically)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_covid_sub_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems with Null Values\n",
    "\n",
    "Null values can interfere with data interpretation and analysis. With pandas, detecting and editing null values is easy.\n",
    "\n",
    "Letâ€™s identify all locations in the survey data that have null (missing or NaN) data values. We can use the isnull method to do this. The isnull method will compare each cell with a null value. If an element has a null value, it will be assigned a value of True in the output object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(state_covid_sub_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To select just the rows with NaN values, we can use the 'any()' method\n",
    "state_covid_sub_df[pd.isnull(state_covid_sub_df).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What will this do?\n",
    "temp_var = state_covid_sub_df[pd.isnull(state_covid_sub_df['death'])]['death']\n",
    "print(temp_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with null values\n",
    "\n",
    "We can replace all NaN values with zeroes using the .fillna() method (after making a copy of the data so we donâ€™t lose our work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The name - \"no_null_state_covid_sub_df\" is probably more explanatory. But we will use a shorter name.\n",
    "nnl_covid_df = state_covid_sub_df.copy()\n",
    "nnl_covid_df['death'] = state_covid_sub_df['death'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test mean of the column with null values not filled in\n",
    "state_covid_sub_df['death'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test mean of the column with null values filled in as 0\n",
    "nnl_covid_df['death'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write DataFrame to outfile \n",
    "(https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html)\n",
    "\n",
    "**note:** make sure you provide the path or are in the working directory you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile_path = pandas_dir + 'state_covid_sub.csv'\n",
    "#outfile_path = os.path.join(pandas_dir,'state_covid_sub.csv')\n",
    "state_covid_sub_df.to_csv(path_or_buf=outfile_path,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulate DataFrame \n",
    "\n",
    "While read_csv is a powerful tool, we are going to subset, rename, change dtypes, and filter on our own just as a practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_covid_df = pd.read_csv('states_covid.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select only columns date, state, death, negative, postive, totalTestResults "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_covid_df = state_covid_df[['date','state','death','positive','negative','totalTestResults']]\n",
    "new_covid_df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### two ways to change column names totalTestResults to total \n",
    "first changes all colums:  \n",
    "`new_covid_df.columns = ['date','state','death','positive','negative','total']`  \n",
    "\n",
    "Second code below:  \n",
    "changes only selected column  \n",
    "axis = (0 = rows, 1 = columns)  \n",
    "inplace=True replaces the current DataFrame, same as (df = df.DOSOMETHING) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_covid_df.rename({'totalTestResults':'total'},axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_covid_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### two ways to reorder columns\n",
    "`new_covid_df = new_covid_df[['date','state','total','negative','positive','death']]`  \n",
    "`new_covid_df = new_covid_df.iloc[:,[0,1,5,4,3,2]]` #iloc is how you access df like a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_covid_df.iloc[2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_covid_df = new_covid_df[['date','state','total','negative','positive','death']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add a column (positivity rate)\n",
    "`new_covid_df['rate'] = new_covid_df.positive / new_covid_df.total` #alternate way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_covid_df['rate'] = new_covid_df['positive'] / new_covid_df['total']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Date manipulation\n",
    "There's lots of crazy stuff you can do with dates, not going into it too much but just letting you know you can do it and something worth looking into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_covid_df[\"date\"]= pd.to_datetime(new_covid_df[\"date\"],yearfirst=True) \n",
    "new_covid_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add a column for day of year/julian date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_covid_df['dayofyear'] = new_covid_df['date'].dt.dayofyear\n",
    "new_covid_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### subsetting/filtering data\n",
    "subset or filter on multiple columns and data types (numeric or string)\n",
    "\n",
    "First, we'll subset on Nevada only and peak in to what it is doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_covid_df.state == 'NV'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can't really see where but it is outputtig a list of boolean (True,False) in the order they are found. If you put this statement as an index, it will keep only the Trues\n",
    "\n",
    "**subsetting NV only**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NV_covid_df = new_covid_df[new_covid_df.state == 'NV']\n",
    "NV_covid_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do one more filtering on states and something else numeric\n",
    "\n",
    "| means or   \n",
    "& means and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_covid_df[(new_covid_df.state == 'NV') & (new_covid_df.rate > 0.10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.query() is another way that might look a little cleaner for more complicated filtering  \n",
    "be careful with syntax of quotations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_covid_df.query(\"state == 'NV' & rate > 0.10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort dataframe \n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sort_values.html\n",
    "\n",
    "**sort and select top 5 positive days**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_covid_df = new_covid_df.sort_values('positive',ascending=False,inplace=False)\n",
    "new_covid_df.sort_values('positive',ascending=False,inplace=True)\n",
    "new_covid_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a DataFrame\n",
    "\n",
    "There are a few different ways to create a DataFrame from scratch or non-csv/excel formatted data\n",
    "\n",
    "### DataFrame from NumPy  \n",
    "ndarray formats translate nicely into DataFrames. Let's generate some fake data using the random function in NumPy to demonstrate. Say this made up data is different sites and persons ratings (0-5) of 8 GREAT Nicholas Cage movies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###generate a random array (8 rows, 6 columns) with values ranging 0-4  \n",
    "movieRank_np = random.randint(5, size=(8,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets make up some column names for this data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['RottenTomatoes','IMBD','MovieCritic','Julie','Trevor','Jahner']\n",
    "movieRank_df = pd.DataFrame(movieRank_np,columns=col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets add a column for movie titles and make them the index as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = ['FaceOff','RaisingArizona','WeatherMan','WickerMan','Adaptation','Gone60Seconds','ConAir','TheRock']  \n",
    "movieRank_df['movie'] = movies  \n",
    "movieRank_df.index = movies\n",
    "movieRank_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieRank_df.mean(axis=0) #mean rank per movie, axis = [row = 0 ,column = 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We all know these numbers are of course wrong because there's no rank below a 5 that should be given, but just an example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing DataFrame\n",
    "\n",
    "https://www.shanelynn.ie/summarising-aggregation-and-grouping-data-in-python-pandas/\n",
    "\n",
    "You will need **Bloom_etal_2018_Reduced_Dataset.csv** from Homework 3 python  \n",
    "\n",
    "Summarizing data is important for figures, statistics, and general reporting\n",
    "\n",
    "make sure you're in the right directory and have the correct csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd $pandas_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bloom_df = pd.read_csv('Bloom_etal_2018_Reduced_Dataset.csv')\n",
    "print(bloom_df.shape)\n",
    "print(bloom_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out how many options there are for the *Reg* column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bloom_df['Reg'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets get some summary stats for *logbodysize* and *tropic_position* based on being diadromous or non-diadromous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bloom_reg_df = bloom_df.groupby('Reg',as_index=True).agg(['mean','count'])\n",
    "bloom_reg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bloom_reg_df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WARNING:** as you can see, this produced the desired result but the column names are now stacked and have what is known as a *MultiIndex* column name and needs to be flattened. You only need to worry about this if summarizing over more than one column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bloom_reg_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's join the MultiIndex to a single column index like we are used to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bloom_reg_df.columns = bloom_reg_df.columns.map('_'.join)\n",
    "bloom_reg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = bloom_reg_df['logbodysize_count']\n",
    "print(x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lastly, couple other useful (maybe) things\n",
    "\n",
    "### matplotlib\n",
    "\n",
    "Not going to go too much into this but just so you know it exists. matplotlib is the most common plotting function in python I think. There are many others though! matplotlib is nice cause it's in the SciPy family so works nicely with pandas and NumPy and other things. Also allows you to integrate ggplot and seaborn if you would like. \n",
    "\n",
    "Simple figures with Covid data. Read in the data again, run through same code to get only NV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_covid_sub_df = pd.read_csv('states_covid.csv',usecols=['date','state','death','positive','negative','totalTestResults'],parse_dates=['date'],infer_datetime_format=True,index_col=None)\n",
    "state_covid_sub_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you index as date. Plot will automatically recogize it for axis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NV_covid_df = state_covid_sub_df[state_covid_sub_df.state == 'NV']\n",
    "NV_covid_df.index = NV_covid_df['date']\n",
    "NV_covid_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load matplotlib.pyplot, plot death over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make the graphs a bit prettier, and bigger\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (15, 5)\n",
    "\n",
    "#### plot deaths over time ####\n",
    "NV_covid_df.death.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that python has great built in date attributes. Plot deaths by day and find the days with the most deaths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### deaths by day of the week ####\n",
    "weekday_counts = NV_covid_df.groupby(NV_covid_df['date'].dt.day_name()).aggregate(sum)\n",
    "weekday_counts\n",
    "\n",
    "weekday_counts.death.plot(kind='bar')\n",
    "\n",
    "weekday_counts[weekday_counts.death == weekday_counts.death.max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Days with most deaths are **Tuesday**. Anyone know why? \"most places are closed on the weekend, many counts are reports happen on monday\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other useful libraries\n",
    "\n",
    "- BioPython / SeqIO (molecular biology)\n",
    "- scikit-learn (statistics and machine learning)\n",
    "- TenserFlow (Deep Learning)\n",
    "- BeautifulSoup (Scraping HTML)\n",
    "- seaborn (extension of matplotlib)\n",
    "- plotly (more ploting)\n",
    "- iPython (notebooks / will go over in Julie's course)\n",
    "- r2py (run R script within python)\n",
    "- literally anything you can think of, a library exists for it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ta-daaaa, you're a data science wizard now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
